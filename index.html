<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Document</title>
    <link rel="stylesheet" href="style.css">
</head>

<body>
    <ul>
        <li><a href="Dane.html">dane</a></li>
        <li><a href="Zdjecia.html">zdjecia</a></li>
        <li><a href="Formularz.html">formularz</a></li>
        <li><a href="Autorzy.html">autorzy</a></li>
    </ul>

    <h1 class="home-title">Sztuczna inteligencja</h1>

    <p class="home-text">Sztuczna intelig encja, SI (ang. artificial intelligence, AI) - inteligencja wykazywana przez
        urządzenia
        obliczeniowe (w przeciwieństwie do inteligencji naturalnej). W potocznym rozumieniu jest ona często używana w
        kontekście ogólnej sztucznej inteligencji. W informatyce i kognitywistyce oznacza także tworzenie modeli i
        programów symulujących choć częściowo zachowania inteligentne. Sztuczna inteligencja jest także
        przedmiotem rozważań filozofii (filozofia sztucznej inteligencji) oraz przedmiotem zainteresowania nauk
        społecznych. Termin „sztuczna inteligencja” wymyślił John McCarthy w 1956 na konferencji w Dartmouth. Andreas
        Kaplan i Michael Haenlein definiują sztuczną inteligencję jako „zdolność systemu do prawidłowego interpretowania
        danych pochodzących z zewnętrznych źródeł, nauki na ich podstawie oraz wykorzystywania tej wiedzy, aby wykonywać
        określone zadania i osiągać cele poprzez elastyczne dostosowanie”. Sztuczną inteligencją zajmowali się m.in.
        Marvin Minsky, John McCarthy, Alan Turing, Edward Feigenbaum, Raj Reddy, Judea Pearl, Allen Newell, Herbert A.
        Simon.
    </p>

    <section class="columns">
        <div class="column-1">
            <h2>Sieci neuronowe</h2>
            <p>
                <a href="https://pl.wikipedia.org/wiki/Sie%C4%87_neuronowa">Sieć neuronowa</a> opiera się na zbiorze połączeń, znanych również jako sztuczne neurony, które stanowią
                analogię neuronów w biologicznym <a href="https://pl.wikipedia.org/wiki/M%C3%B3zgowie_cz%C5%82owieka">mózgu</a>. Jest ona trenowana do rozpoznawania wzorców, a po przeszkoleniu
                może rozpoznawać te wzorce w świeżych danych. W najprostszej postaci posiada wejście, co najmniej jedną
                ukrytą warstwę połączeń i wyjście. Każde połączenie posiada funkcję aktywacji, która pozwala na
                przesyłane informacji do następnej warstwy. Sieć jest zazwyczaj nazywana głęboką siecią neuronową, jeśli
                ma co najmniej 2 ukryte warstwy.
            </p>
        </div>
        <div class="column-2">
            <h2>Duże modele językowe</h2>
            <p>
                <a href="https://pl.wikipedia.org/wiki/Du%C5%BCy_model_j%C4%99zykowy">Duże modele językowe</a> (LLM) jak wstępnie przeszkolony transformator generatywny (GPT) generują tekst
                oparty na związkach semantycznych pomiędzy słowami i zdaniami. Tekstowe duże modele językowe bazują na
                dużym korpusie pobranym z różnych stron w Internecie. Wstępny trening polega na nauczeniu predykcji
                następnego tokena, po czym następuje docelowy trening mający na celu poprawę użyteczności, wiarygodności
                i poprawie bezpieczeństwa. Do tego celu stosowana jest technika RLHF. Według stanu na 2025 rok LLM-y są
                podatne na generowanie fałszywych informacji nazywanych halucynacjami, a sam problem potrafi się
                pogarszać w miarę używania tych modeli do rozumowania.
            </p>
        </div>
    </section>

</body>

</html>